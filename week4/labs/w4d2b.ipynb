{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bb54434c",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Always run this code.\n",
        "%config InteractiveShell.ast_node_interactivity=\"none\"\n",
        "import sys\n",
        "if 'google.colab' in sys.modules:\n",
        "  !pip install --force-reinstall git+https://github.com/jamcoders/jamcoders-public-2025.git --quiet\n",
        "from jamcoders.base_utils import *\n",
        "from jamcoders.week4.labw4d2b import *\n",
        "import random"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "UIzql3gihXJD",
      "metadata": {
        "id": "UIzql3gihXJD"
      },
      "source": [
        "# Week 4, Day 2B: Bigram Graph Traversals"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d6ca0d6f",
      "metadata": {},
      "source": [
        "In today's lab, we will use a graph that represents a bigram model, where each node is a word, and each edge shows the probability of going from one word to the next.\n",
        "\n",
        "In an undirected graph, an adjacency list might look like this:\n",
        "\n",
        "```python\n",
        "adj_list = [\n",
        "    [2, 3],    # Node 0 connects to nodes 2 and 3\n",
        "    [3, 4],    # Node 1 connects to nodes 3 and 4\n",
        "    [4],       # Node 2 connects to node 4\n",
        "    [0, 5],    # Node 3 connects to nodes 0 and 5\n",
        "    []         # Node 4 connects to no one (dead end)\n",
        "]\n",
        "```\n",
        "\n",
        "In a bigram model, we need to know more than just where you can go. We also need to know the probability of going there from one word to another word. So instead of storing a list of neighbors, we store a dictionary which maps current word to a dictionary containing {next_word: probability:\n",
        "\n",
        "```python\n",
        "weighted_adj_list = {\n",
        "    \"<START>\": {\"I\": 1},  # The sentence always starts with \"I\"\n",
        "    \"I\": {\"am\": 0.5, \"like\": 0.5},  # After \"I\", \"am\" and \"like\" are equally likely\n",
        "    \"am\": {\"happy\": 0.7, \"sad\": 0.2, \"bananas\": 0.1},  # After \"am\", \"happy\" is most likely, then \"sad\", then \"bananas\"\n",
        "    \"like\": {\"bananas\": 0.6, \"math\": 0.4}  # After \"like\", \"bananas\" is more likely than \"math\"\n",
        "}\n",
        "```\n",
        "\n",
        "This allows us to construct a _weighted directed graph_."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a923ae4c",
      "metadata": {},
      "outputs": [],
      "source": [
        "weighted_adj_list = {\n",
        "    \"<START>\": {\"I\": 1.0},\n",
        "    \"I\": {\"am\": 0.5, \"like\": 0.5},\n",
        "    \"am\": {\"happy\": 0.7, \"sad\": 0.2, \"bananas\": 0.1},\n",
        "    \"like\": {\"bananas\": 0.6, \"math\": 0.4}\n",
        "}\n",
        "\n",
        "G = generate_graph(weighted_adj_list)\n",
        "plot_graph(G)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "474e2fc1",
      "metadata": {},
      "source": [
        "**1.1**\n",
        "\n",
        "To start, consider the following questions about the above graph."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a259fabd",
      "metadata": {},
      "source": [
        "Assign `num_nodes` to the number of nodes in the graph."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4accead1",
      "metadata": {},
      "outputs": [],
      "source": [
        "num_nodes = ..."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "311bdf16",
      "metadata": {},
      "source": [
        "Assign `num_edges` to the number of edges in the graph."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d3a2347b",
      "metadata": {},
      "outputs": [],
      "source": [
        "num_edges = ..."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c7d9b1cb",
      "metadata": {},
      "source": [
        "Assign `longest_path_length` to the number of edges encountered on the longest path in the graph."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b115b7ae",
      "metadata": {},
      "outputs": [],
      "source": [
        "longest_path_length = ..."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9298c366",
      "metadata": {},
      "source": [
        "Is there a cycle in this graph? If so, assign `cycle_exists` to `True`. Otherwise, assign it to False."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fca086f5",
      "metadata": {},
      "outputs": [],
      "source": [
        "cycle_exists = ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7c99330d",
      "metadata": {},
      "outputs": [],
      "source": [
        "check_answer_1_1([num_nodes, num_edges, longest_path_length, cycle_exists])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "442c3ede",
      "metadata": {},
      "source": [
        "**1.2**\n",
        "\n",
        "Write a function `random_next_word`, which takes as input a key of the dictionary `weighted_adj_list`, and randomly generates the next word. The probability of possible next words is located in the values of `weighted_adj_list`.\n",
        "\n",
        "**HINT:** the line of code `sample_from_dict({\"bananas\" : 0.6, \"math\" : 0.4})` will randomly sample from the list `[\"bananas\", \"math\"]`, and select `\"bananas\"` 60% of the time and select `\"math\"` 40% of the time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "270b9bd4",
      "metadata": {},
      "outputs": [],
      "source": [
        "def random_next_word(weighted_adj_list, current_word):\n",
        "    \"\"\"\n",
        "    Randomly selects the next word from a weighted adjacency list.\n",
        "\n",
        "    Args:\n",
        "        weighted_adj_list (dict): A dictionary where each key is a word,\n",
        "            and each value is another dictionary mapping possible next words\n",
        "            to their probabilities.\n",
        "        current_word (str): The current word to look up in the adjacency list.\n",
        "\n",
        "    Returns:\n",
        "        str: A randomly selected next word based on the given probabilities.\n",
        "    \"\"\"\n",
        "    # YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4188b25f",
      "metadata": {},
      "outputs": [],
      "source": [
        "random.seed(21)\n",
        "assert_equal(got=random_next_word(weighted_adj_list, \"<START>\"), want=\"I\")\n",
        "assert_equal(got=random_next_word(weighted_adj_list, \"I\"), want=\"like\")\n",
        "assert_equal(got=random_next_word(weighted_adj_list, \"I\"), want=\"like\")\n",
        "assert_equal(got=random_next_word(weighted_adj_list, \"am\"), want=\"happy\")\n",
        "assert_equal(got=random_next_word(weighted_adj_list, \"am\"), want=\"happy\")\n",
        "assert_equal(got=random_next_word(weighted_adj_list, \"am\"), want=\"sad\")\n",
        "assert_equal(got=random_next_word(weighted_adj_list, \"like\"), want=\"math\")\n",
        "assert_equal(got=random_next_word(weighted_adj_list, \"like\"), want=\"bananas\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a9a85cea",
      "metadata": {},
      "source": [
        "**1.3**\n",
        "\n",
        "Write a function called `get_random_sentence`. Starting at `<START>`, it should use `random_next_word` to randomly generate a 3 word sentence and return that sentence as a string. Your answer does not need to include punctuation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "085ff24e",
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_random_sentence(weighted_adj_list):\n",
        "    \"\"\"Generate a 3-word sentence starting from <START> using weighted random choices.\n",
        "    \n",
        "    Returns:\n",
        "        A list of 3 words, e.g. [\"I\", \"am\", \"happy\"].\n",
        "    \"\"\"\n",
        "    # YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8021f1b6",
      "metadata": {},
      "outputs": [],
      "source": [
        "random.seed(21)\n",
        "assert_equal(got=get_random_sentence(weighted_adj_list), want=[\"I\", \"like\", \"math\"])\n",
        "assert_equal(got=get_random_sentence(weighted_adj_list), want=[\"I\", \"am\", \"sad\"])\n",
        "assert_equal(got=get_random_sentence(weighted_adj_list), want=[\"I\", \"like\", \"bananas\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "69cf32e3",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Here, we re-plot G to minimize scrolling\n",
        "plot_graph(G)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4ba3f9d0",
      "metadata": {},
      "source": [
        "**1.4**\n",
        "\n",
        "In a bigram model, we assume that the probability of a word occuring depends solely on the previous word.  To calculate the probability of a specific sentence occuring, we multiply the probabilities (edge weights) of each word transition as we follow the words in a sentence.\n",
        "\n",
        "The probability of observing the sentence `\"I am happy\"` is equal to `1 * 0.5 * 0.7`, because the probability of moving from `\"<START>\"` to `\"I\"` is `1`, the probability of moving from `\"I\"` to `\"am\"` is `0.5`, and the probability of moving from `\"am\"` to `\"happy\"` is `0.7`.\n",
        "\n",
        "Using this idea, write a function `get_probability` that takes in the `weighted_adj_list` and a list of words called `sentence` and returns the probability of that sentence being generated given the bigram probabilities."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0jiGhtLEBJyP",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0jiGhtLEBJyP",
        "outputId": "6a2aa84e-4b54-4b89-8a66-8ae562f073fa"
      },
      "outputs": [],
      "source": [
        "def get_probability(weighted_adj_list, sentence):\n",
        "    \"\"\"Return the probability of generating a given sentence based on bigram probabilities.\n",
        "\n",
        "    Args:\n",
        "        weighted_adj_list (dict): A dictionary mapping words to dictionaries of next-word probabilities.\n",
        "        sentence (list): A list of words representing a sentence (e.g., [\"I\", \"am\", \"happy\"]).\n",
        "\n",
        "    Returns:\n",
        "        float: The product of bigram probabilities from <START> through the sentence.\n",
        "    \"\"\"\n",
        "    # YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Qm3PpEt7iYPB",
      "metadata": {
        "id": "Qm3PpEt7iYPB"
      },
      "outputs": [],
      "source": [
        "assert_equal(got=get_probability(weighted_adj_list, [\"I\", \"am\", \"happy\"]), want=1 * 0.5 * 0.7)\n",
        "assert_equal(got=get_probability(weighted_adj_list, [\"I\", \"like\", \"bananas\"]), want=1 * 0.5 * 0.6)\n",
        "assert_equal(got=get_probability(weighted_adj_list, [\"I\", \"am\", \"bananas\"]), want=1 * 0.5 * 0.1)\n",
        "assert_equal(got=get_probability(weighted_adj_list, [\"I\", \"like\", \"math\"]), want=1 * 0.5 * 0.4)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "convokit_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.23"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
