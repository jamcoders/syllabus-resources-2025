{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fac488d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Always run this code.\n",
    "%config InteractiveShell.ast_node_interactivity=\"none\"\n",
    "import sys\n",
    "if 'google.colab' in sys.modules:\n",
    "  !pip install --force-reinstall git+https://github.com/jamcoders/jamcoders-public-2025.git --quiet\n",
    "from jamcoders.base_utils import *\n",
    "from jamcoders.week4.labw4d2a import *\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4fbde7",
   "metadata": {},
   "source": [
    "# Week 4, Day 2A: NGrams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c30d9509",
   "metadata": {},
   "source": [
    "## Question 1: Analyzing a Text Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ad4a5b",
   "metadata": {},
   "source": [
    "Run the next cell to load the [DailyDialog](https://paperswithcode.com/dataset/dailydialog) dataset, which contains a collection of conversations. Special symbols `<START>` and `<END>` represent the beginning of a sequence and end of a sequence, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec5540e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e47b3c77",
   "metadata": {},
   "source": [
    "Run the following cell to get an idea of what the dataset looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7817c240",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset[:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f0fb637",
   "metadata": {},
   "source": [
    "**1.1**\n",
    "\n",
    "Follow the following pseudocode to print the first 5 sequences:\n",
    "\n",
    "1. Initialize `end_count` to 0. This will represent the number of `<END>` words encountered in the dataset.\n",
    "2. Initialize `i` to 0. This will represent the index into the dataset.\n",
    "3. While `end_count < 5`, do the following:\n",
    "   1. Let `word` be `dataset[i]`.\n",
    "   2. If `word` is not `\"<END>\"` and not `\"<START>\"`, then:\n",
    "        - Print `word` followed by a space (on the same line).\n",
    "   3. Else if `word` is `\"<END>\"`, then:\n",
    "      - Increment `end_count` by 1.\n",
    "      - Print a newline to start a new sequence.\n",
    "   4. Increment `i` by 1.\n",
    "\n",
    "**HINT:** `print(\"Hello\", end=\" \")` prints `\"Hello \"` without moving to a new line. Calling `print()` prints a new line but nothing else.\n",
    "\n",
    "Your output should looks like this:\n",
    "```\n",
    "how does it fit it fits fine i'll take it how much is it \n",
    "look i bought these shoes only three weeks ago and there is a hole in them already if that happen to me i'll take them back to the shop \n",
    "i have a little problem with room 507 problems are what we're here for sir please tell me your problem \n",
    "how would you like to send it by airmail \n",
    "you need to fill out this form please all i want is the same thing on this card \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e289b3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eeb1de2",
   "metadata": {},
   "source": [
    "**1.2**\n",
    "\n",
    "Implement the function `get_word_counts`, which takes in a list of strings and assigns `word_counts` to a dictionary which maps each word to the number of times it appears in a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530ddea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_counts(lst):\n",
    "    \"\"\"\n",
    "    Counts the occurrences of each word in the input list.\n",
    "\n",
    "    Args:\n",
    "        lst (list[str]): An list of words.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary mapping each word to the number of times it appears in lst.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a1713e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify that your implementation passes ALL of these tests before moving on\n",
    "fruit_lst = ['apple', 'banana', 'apple', 'cherry', 'banana', 'cherry', 'cherry', 'apple', 'cherry', 'cherry']\n",
    "fruit_counts = get_word_counts(fruit_lst)\n",
    "expected_counts = {'apple': 3, 'banana': 2, 'cherry': 5}\n",
    "assert_equal(got=fruit_counts, want=expected_counts)\n",
    "\n",
    "empty_lst = []\n",
    "empty_counts = get_word_counts(empty_lst)\n",
    "assert_equal(got=empty_counts, want={})\n",
    "\n",
    "single_word_lst = ['only'] * 7\n",
    "single_counts = get_word_counts(single_word_lst)\n",
    "assert_equal(got=single_counts, want={'only': 7})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f1a847",
   "metadata": {},
   "source": [
    "Now, run the following cells to initialize a dictionary called `word_counts` that maps words to counts for the entire dataset. Check out the word counts of the following words!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b40584",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts = get_word_counts(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed7ff4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(word_counts['i'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0c0d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(word_counts['love'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb31ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(word_counts['math'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fefa4790",
   "metadata": {},
   "source": [
    "**1.3**\n",
    "\n",
    "Run the cell below to visualize the 15 most common words in the dataset and their frequencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01af408",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_barplot(word_counts, top_n=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66371029",
   "metadata": {},
   "source": [
    "What does this chart suggest about how language is distributed in the dataset? Answer in 1-2 sentences. This is an open-ended question -- there is no single correct answer!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd5144c",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1a679a",
   "metadata": {},
   "source": [
    "**1.4**\n",
    "\n",
    "Write a function called `cumulative_sum` which takes in a list of numbers and returns a new list where the i-th element is the sum of the first i + 1 elements from the input list.\n",
    "\n",
    "For example,`cumulative_sum([1, 3, 5])` would return `[1, 1 + 3, 1 + 3 + 5] --> [1, 4, 9]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6f7f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cumulative_sum(lst):\n",
    "    \"\"\"\n",
    "    Returns the cumulative sum of a list of numbers.\n",
    "\n",
    "    Parameters:\n",
    "        lst (list): A list of numbers sorted in non-decreasing order.\n",
    "\n",
    "    Returns:\n",
    "        list: A new list where the i-th element is the sum of the first i+1 elements of the input list.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90899932",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify that your implementation passes ALL of these tests before moving on\n",
    "a = [1, 3, 5]\n",
    "assert_equal(got=cumulative_sum(a), want=[1, 4, 9]) \n",
    "assert_equal(got=a, want=[1, 3, 5]) # This should stay the same\n",
    "\n",
    "assert_equal(got=cumulative_sum([]), want=[])\n",
    "assert_equal(got=cumulative_sum([5]), want=[5])\n",
    "assert_equal(got=cumulative_sum([0, 0, 0]), want=[0, 0, 0])\n",
    "assert_equal(got=cumulative_sum([-3, -2, -1]), want=[-3, -5, -6])\n",
    "assert_equal(got=cumulative_sum([-2, 0, 3]), want=[-2, -2, 1])\n",
    "assert_equal(got=cumulative_sum([2, 2, 2, 2]), want=[2, 4, 6, 8])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f523f748",
   "metadata": {},
   "source": [
    "**1.5**\n",
    "\n",
    "Run the code below to generate a CDF (Cumulative Distribution Function) plot. This plot uses your `cumulative_sum` function to show how the most common words add up to make a larger and larger share of the dataset.\n",
    "\n",
    "- The **x-axis** shows words in order from most to least frequent.  \n",
    "- The **y-axis** shows the cumulative percentage of all word occurrences counted so far.\n",
    "\n",
    "**For example:**\n",
    "- At **x = 1**, the CDF shows what percent of all words are just the single most frequent word.\n",
    "- At **x = 10**, it shows the percent made up by the 10 most common words.\n",
    "- The line rises as you go right, eventually reaching **100%** once all words are included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b91256f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_word_counts = sorted(word_counts.values(), reverse=True)\n",
    "cumulative_percent_of_words = 100 * np.array(cumulative_sum(sorted_word_counts)) / sum(sorted_word_counts)\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(cumulative_percent_of_words)\n",
    "plt.xlabel(\"Rank of Word (Most to Least Frequent)\")\n",
    "plt.ylabel(\"Cumulative Percentage\")\n",
    "plt.title(\"Cumulative Distribution of Word Frequencies\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef58f4fa",
   "metadata": {},
   "source": [
    "Use the CDF plot to answer the questions below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4559c3ba",
   "metadata": {},
   "source": [
    "Approximately how many unique words are in the dataset? A rough answer is fine, no need to be exact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea686d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_unique_words = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6542949e",
   "metadata": {},
   "source": [
    "Roughly what percentage of all words in the dataset are accounted for by the 2,500 most frequent words? Your answer should be a percentage between 0 and 100. A rough answer is fine, no need to be exact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef1c271",
   "metadata": {},
   "outputs": [],
   "source": [
    "percent_covered_by_2500 = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ae4a79",
   "metadata": {},
   "source": [
    "Run the below code to check your answers. Do not move on until they are both correct. Feel free to call over a TA if you need help!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5104cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_answer_1_6([num_unique_words, percent_covered_by_2500])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d57b371",
   "metadata": {},
   "source": [
    "**1.6**\n",
    "\n",
    "Run the cell below to make a cool visualization!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f8fdbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_wordcloud(word_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd0e835a",
   "metadata": {},
   "source": [
    "## Question 2: Unigram Language Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f5f706",
   "metadata": {},
   "source": [
    "In this section, we will make a unigram language model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae51e54",
   "metadata": {},
   "source": [
    "**2.1**\n",
    "\n",
    "Complete the `probability` function, which takes a `word` and and a dictionary `word_counts`, and returns the probability of that word occuring. The probability of a word in a dataset tells you how often you’d expect to see that word if you randomly picked one word from the text. If the word is not found in the dictionary, its count is assumed to be 0.\n",
    "\n",
    "**HINT:** using Python's build in `sum` function on the values of `word_counts` (i.e. `sum(word_counts.values())`) is one way to get the total number of words in the dataset.\n",
    "\n",
    "**HINT:** if you are confused about how to get started, check out the test cases in the cell below!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55af3f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def probability(word, word_counts):\n",
    "    \"\"\"\n",
    "    Compute the probability of a word being sampled from the dataset. \n",
    "    This represents how likely you are to encounter that word if you \n",
    "    randomly select a single word from the text.\n",
    "\n",
    "    This function takes a word and a dictionary of word counts,\n",
    "    and returns the probability of that word occurring. If the word\n",
    "    is not found in the dictionary, its count is assumed to be 0.\n",
    "\n",
    "    Parameters:\n",
    "        word (str): The word whose probability we want to compute.\n",
    "        word_counts (dict): A dictionary mapping each word to the\n",
    "          number of times it appears.\n",
    "\n",
    "    Returns:\n",
    "        float: The probability of the word, computed as its count\n",
    "               divided by the total count of all words.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab7db79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify that your implementation passes ALL of these tests before moving on\n",
    "fruit_counts = {'apple': 3, 'banana': 2, 'cherry': 5}\n",
    "\n",
    "assert_equal(got=probability('apple', fruit_counts), want=3 / 10)\n",
    "assert_equal(got=probability('banana', fruit_counts), want=2 / 10)\n",
    "assert_equal(got=probability('cherry', fruit_counts), want=5 / 10)\n",
    "assert_equal(got=probability('date', fruit_counts), want=0.0)\n",
    "\n",
    "assert_equal(got=probability('', {'': 1, 'other': 1}), want=0.5)\n",
    "assert_equal(got=probability('only', {'only': 7}), want=1.0)\n",
    "\n",
    "assert_equal(got=probability('i', word_counts), want=0.03212862707261292)\n",
    "assert_equal(got=probability('love', word_counts), want=0.0007111206403659234)\n",
    "assert_equal(got=probability('math', word_counts), want=3.8414808461978273e-05)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6792760",
   "metadata": {},
   "source": [
    "**2.2**\n",
    "\n",
    "Write a function called `get_word_probabilities` which returns a dictionary that maps each word in `word_counts` to the probability that a given word in the dataset is that word.\n",
    "\n",
    "**HINT:** if you are confused about how to get started, check out the test cases in the cell below!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a56eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_probabilities(word_counts):\n",
    "    \"\"\"\n",
    "    Computes the probability of each word in the dataset appearing as the next word.\n",
    "\n",
    "    Parameters:\n",
    "        word_counts (dict): A dictionary mapping words to their counts in the dataset.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary mapping each word to its probability based on its frequency in word_counts.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c297ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify that your implementation passes ALL of these tests before moving on\n",
    "fruit_counts = {'apple': 3, 'banana': 2, 'cherry': 5}\n",
    "fruit_probs = get_word_probabilities(fruit_counts)\n",
    "assert_equal(len(fruit_probs), 3)\n",
    "assert_equal(got=fruit_probs['apple'], want=3 / 10)\n",
    "assert_equal(got=fruit_probs['banana'], want=2 / 10)\n",
    "assert_equal(got=fruit_probs['cherry'], want=5 / 10)\n",
    "\n",
    "empty_counts = {'': 1, 'other': 1}\n",
    "probs = get_word_probabilities(empty_counts)\n",
    "assert_equal(got=len(probs), want=2)\n",
    "assert_equal(got=probs[''], want=0.5)\n",
    "assert_equal(got=probs['other'], want=0.5)\n",
    "\n",
    "single_word_counts = {'only': 7}\n",
    "probs = get_word_probabilities(single_word_counts)\n",
    "assert_equal(got=len(probs), want=1)\n",
    "assert_equal(got=probs['only'], want=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda1c73d",
   "metadata": {},
   "source": [
    "The below cell generates a dictionary mapping words in `dataset` to its probability, and performs a few sanity checks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2251010d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify that your implementation passes ALL of these tests before moving on\n",
    "word_probabilities = get_word_probabilities(word_counts)\n",
    "\n",
    "assert_equal(got=sum(word_probabilities.values()), want=1.0)\n",
    "assert_equal(got=len(word_probabilities), want=19790)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41de9898",
   "metadata": {},
   "source": [
    "**2.3**\n",
    "\n",
    "Here we'll implement the logic to run the chatbot. To help you, we've implemented some functions. You should NOT edit these functions, and you don't need to understand how they work; just what arguments they take and return.\n",
    "\n",
    "`generate_unigram_response`\n",
    "\n",
    "- Generates text using a unigram language model when given `word_probabilities`, a dictionary mapping words to their probabilities.\n",
    "- `max_length` can is the maximum length of the chatbot response. If the user does not specify the `max_length`, it defaults to 15.\n",
    "\n",
    "`run_unigam_chatbot`\n",
    "\n",
    "* Continuously prompts the user for input and generates a response using `generate_unigram_response` until the user types 'quit'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044ed0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_unigram_response(word_probabilities, max_length=15):\n",
    "    \"\"\"\n",
    "    Generates a sequence of words using a unigram language model.\n",
    "\n",
    "    Each word is sampled independently based on its probability, ignoring previous context.\n",
    "    The generation stops when the maximum number of words is reached or when the <END> \n",
    "    (end of sentence) is sampled.\n",
    "\n",
    "    Parameters:\n",
    "        word_probabilities (dict): A dictionary mapping words to their unigram probabilities.\n",
    "        max_length (int): The maximum number of words to generate (default is 15).\n",
    "\n",
    "    Returns:\n",
    "        str: A generated string formed by joining the sampled words, with basic formatting applied\n",
    "            to remove special words like <START> and <END>.\n",
    "    \"\"\"\n",
    "        \n",
    "    response_words = []\n",
    "    for _ in range(max_length):\n",
    "        words = list(word_probabilities.keys())\n",
    "        probabilities = list(word_probabilities.values())\n",
    "        word = random.choices(words, weights=probabilities)[0]\n",
    "\n",
    "        response_words.append(word)\n",
    "        \n",
    "        if word ==  '<END>':\n",
    "            break\n",
    "    \n",
    "    response = ' '.join(response_words).replace(' <START>', '').replace(' .', '.').replace(\" '\", \"'\").replace('<END>', '')\n",
    "    return response.strip()\n",
    "\n",
    "def run_unigram_chatbot():\n",
    "    \"\"\"\n",
    "    Starts an interactive loop for chatting with a simple unigram-based chatbot.\n",
    "\n",
    "    The chatbot generates responses by sampling words independently from a unigram language model.\n",
    "    The conversation continues until the user types 'quit'.\n",
    "    \"\"\"\n",
    "    print(\"Hello! I'm a simple chatbot. Let's chat!\")\n",
    "    print(\"(Type 'quit' to end the conversation)\\n\")\n",
    "    \n",
    "    while True:\n",
    "        user_input = input(\"\\nYou: \")\n",
    "        \n",
    "        if user_input.lower() == 'quit':\n",
    "            print(\"Chatbot: Goodbye! Thanks for chatting!\")\n",
    "            return\n",
    "        \n",
    "        if not user_input.strip():\n",
    "            print(\"Chatbot: I'm listening...\") # Re-prompt when given empty input\n",
    "            continue\n",
    "        \n",
    "        response = generate_unigram_response(word_probabilities)\n",
    "        \n",
    "        print(f\"Chatbot: \", response, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fced66a",
   "metadata": {},
   "source": [
    "Run the cell below to interact with the chatbot!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037c31e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_unigram_chatbot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6699034b",
   "metadata": {},
   "source": [
    "**2.4**\n",
    "\n",
    "Answer the following questions in 2-3 sentences total. Why is the unigram model not making real sense? What does our model assume the way humans speak? Why is that not a very good assumption?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81dee099",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274686a9",
   "metadata": {},
   "source": [
    "## Question 3: NGram Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c688c167",
   "metadata": {},
   "source": [
    "Let’s say you’re trying to predict what word comes next in a sentence.\n",
    "\n",
    "You see:\n",
    "\n",
    "> *see you  ___________*\n",
    "\n",
    "What could the next word be? Some possibilities:\n",
    "\n",
    "- **soon** → *see you soon*\n",
    "- **later** → *see you later*\n",
    "- **again** → *see you again*\n",
    "- **never** → *see you never*\n",
    "\n",
    "These all make sense, but they mean different things. NGrams give us a way to use the context of the preceding words to quantify the most likely next word.\n",
    "\n",
    "If someone says:\n",
    "\n",
    "> *Thanks for visiting! See you ___________*\n",
    "\n",
    "You’ll probably hear:\n",
    "\n",
    "> **soon** or **later**\n",
    "\n",
    "But if the sentence is:\n",
    "\n",
    "> *After what you did… see you ___________*\n",
    "\n",
    "You might hear:\n",
    "\n",
    "> **never**\n",
    "\n",
    "The meaning of the sentence, and what word comes next, depends on the **context**, or the **words that came before**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c8305d",
   "metadata": {},
   "source": [
    "**3.1**\n",
    "\n",
    "Consider the Python dictionary `trigram_counts_example`. Each key is a tuple of two words (a 2-word context), and the value is a dictionary of possible third words and how many times they each were seen in the dataset.\n",
    "\n",
    "**Note**: a tuple is like a list, but you can't change it after it's created, and it uses parentheses instead of square brackets. For reasons outside the scope of JamCoders, tuples can be used as keys in dictionaries, but lists cannot. Ask a TA if you are interested in why! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41c43be",
   "metadata": {},
   "outputs": [],
   "source": [
    "trigram_counts_example = {\n",
    "    (\"i\", \"love\"): {\"you\": 3, \"dogs\": 2},\n",
    "    (\"love\", \"you\"): {\"too\": 1, \"so\": 1},\n",
    "    (\"you\", \"too\"): {\"<END>\": 1},\n",
    "    (\"you\", \"so\"): {\"much\": 1},\n",
    "    (\"so\", \"much\"): {\"<END>\": 1},\n",
    "    (\"i\", \"have\"): {\"dogs\": 2},\n",
    "    (\"have\", \"dogs\"): {\"<END>\": 2},\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977d2a16",
   "metadata": {},
   "source": [
    "Answer the following questions below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad0b986a",
   "metadata": {},
   "source": [
    "Assign the the variable `i_love` to a list of the possible next words after the phrase \"i love\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b5bd6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "i_love = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae85da7e",
   "metadata": {},
   "source": [
    "Based on the counts for (\"i\", \"love\"), what is the probability of seeing the word \"dogs\" next? Assign this variable to `prob`. Your answer should be a float between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22b825a",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a42c7b",
   "metadata": {},
   "source": [
    "Given the context \"i love\", what is the most likely next word? Assign this word to `most_likely`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9acb4f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "most_likely = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16f388a",
   "metadata": {},
   "source": [
    "Suppose you start with the words [\"i\", \"love\"]. Using `trigram_counts`, what is a possible 5-word sentence you could build?  Assign `sentence` to a list containing these 5 words. Your answer should not include any capital letters or punctuation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12571a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb7b8a1",
   "metadata": {},
   "source": [
    "Run the below code to check your answers. Do not move on until they are both correct. Feel free to call over a TA if you need help!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac217da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_answer_3_1([i_love, prob, most_likely, sentence])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f02993",
   "metadata": {},
   "source": [
    "**3.2**\n",
    "\n",
    "Below you will find an implementation of an NGram Chatbot. You do not need to code anything in this problem. You can just run the cells in order until you reach the last cell, which allows you to run the chatbot. Along the way, respond the to written questions.\n",
    "\n",
    "We provide a description of each function below for your interest.\n",
    "\n",
    "`build_ngram_counts`\n",
    "- Generates a dictionary of NGram Counts. Given argument `n`, Each key is a tuple of (n-1) words, and the value is a dictionary of possible nth words and how many times they each were seen in the dataset.\n",
    "\n",
    "`get_context`\n",
    "- Get the last n-1 words from text_prefix to use as context for n-gram prediction. If there aren't enough words, pad with `<START>` words at the beginning.\n",
    "\n",
    "`generate_ngram_response`\n",
    "\n",
    "- Generates text using an NGram language model (no context between words) when given `ngram_counts`, a dictionary mapping NGram tuples to their counts.\n",
    "- `max_length` can is the maximum length of the chatbot response. If the user does not specify the `max_length`, it defaults to 15.\n",
    "\n",
    "`run_ngram_chatbot`\n",
    "\n",
    "* Continuously prompts the user for input and generates a response using `generate_unigram_response` until the user types  'quit'. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec54d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_ngram_counts(lst, n):\n",
    "    \"\"\"\n",
    "    Build N-gram counts from a list of words, with <START> padding at the start.\n",
    "\n",
    "    If <START> appears in the context, all words before the last <START> are replaced with <START>.\n",
    "\n",
    "    Args:\n",
    "        list (list): List of words including <END> markers\n",
    "        n (int): Size of n-grams (2 for bigrams, 3 for trigrams, etc.)\n",
    "\n",
    "    Returns:\n",
    "        dict: Nested dictionary {context: {next_word: count}}\n",
    "              where context is tuple of n-1 words\n",
    "    \"\"\"\n",
    "    ngram_counts = {}\n",
    "\n",
    "    for i in range(len(dataset) - n + 1):\n",
    "        ngram = tuple(dataset[i:i + n])\n",
    "        context = list(ngram[:-1])\n",
    "        next_word = ngram[-1]\n",
    "\n",
    "        if '<START>' in context:\n",
    "            last_bos_index = len(context) - 1 - context[::-1].index('<START>')\n",
    "            context[:last_bos_index] = ['<START>'] * last_bos_index\n",
    "\n",
    "        context = tuple(context)\n",
    "\n",
    "        if context not in ngram_counts:\n",
    "            ngram_counts[context] = {}\n",
    "\n",
    "        if next_word in ngram_counts[context]:\n",
    "            ngram_counts[context][next_word] += 1\n",
    "        else:\n",
    "            ngram_counts[context][next_word] = 1\n",
    "\n",
    "    return ngram_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fdd523b",
   "metadata": {},
   "source": [
    "Run the following cells to generate `bigram_counts` and `trigram_counts`, respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c96243",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_counts = build_ngram_counts(dataset, 2)\n",
    "trigram_counts = build_ngram_counts(dataset, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da89336",
   "metadata": {},
   "source": [
    "Observe the following example use cases of `bigram_counts` and `trigram_counts`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a9a64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bigram_counts.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aedefee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bigram_counts[(\"i\",)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b90c849",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bigram_counts[(\"love\",)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4981df5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bigram_counts[(\"you\",)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3db9e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(trigram_counts[(\"i\", \"love\",)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e9d570",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(trigram_counts[(\"go\", \"to\",)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8790db0b",
   "metadata": {},
   "source": [
    "What kind of information do these counts capture? How might they be more useful than a unigram in writing a program that generates or analyzes text? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec1ffe7",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0d0b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_context(prompt, n):\n",
    "    \"\"\"\n",
    "    Get the last n-1 words from prompt to use as context for n-gram prediction.\n",
    "    If there aren't enough words, pad with <START> words at the beginning.\n",
    "    \n",
    "    Args:\n",
    "        prompt (str): Input text (str)\n",
    "        n (int): Size of NGram (2 for bigrams, 3 for trigrams, etc.)\n",
    "    \n",
    "    Returns:\n",
    "        tuple: Last n-1 words as a tuple (context for next word prediction)\n",
    "               Padded with <START> words if not enough words available\n",
    "    \"\"\"\n",
    "    words = clean(prompt).split()\n",
    "\n",
    "    context_words = words[-(n-1):] if len(words) >= n-1 else words\n",
    "    \n",
    "    needed_padding = (n - 1) - len(context_words)\n",
    "    if needed_padding > 0:\n",
    "        context_words = ['<START>'] * needed_padding + context_words\n",
    "    \n",
    "    context = tuple(context_words)\n",
    "    return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124221c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_ngram_response(prompt, ngram_counts, n, max_length=15):\n",
    "    \"\"\"Generate a response using an n-gram language model.\"\"\"\n",
    "\n",
    "    response_words = list(get_context(prompt, n=n))\n",
    "\n",
    "    # Caching a fallback of sampling a random word from all available next words in ngram_counts\n",
    "    all_words = []\n",
    "    all_weights = []\n",
    "    for counts in ngram_counts.values():\n",
    "        for word, count in counts.items():\n",
    "            all_words.append(word)\n",
    "            all_weights.append(count)\n",
    "    \n",
    "    for _ in range(max_length):\n",
    "        current_context = tuple(response_words[-(n-1):])\n",
    "        \n",
    "        possible_next_words = []\n",
    "        weights = []\n",
    "        \n",
    "        for ngram, counts in ngram_counts.items():\n",
    "            if ngram == current_context:\n",
    "                for word, count in counts.items():\n",
    "                    possible_next_words.append(word)\n",
    "                    weights.append(count)\n",
    "\n",
    "        if len(possible_next_words) == 0:\n",
    "            next_word = random.choices(all_words, weights=all_weights)[0]\n",
    "        else:\n",
    "            next_word = random.choices(possible_next_words, weights=weights)[0]\n",
    "\n",
    "        response_words.append(next_word)\n",
    "        \n",
    "        if next_word == '<END>':\n",
    "            break\n",
    "    \n",
    "    final_words = response_words[(n-1):]\n",
    "    response = ' '.join(final_words).replace('<END>', '').replace(' .', '.').replace(\" '\", \"'\").replace('<START>', '')\n",
    "    return response.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a983c1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_ngram_chatbot(word_counts, n):\n",
    "    \"\"\"\n",
    "    Generate a text response using an n-gram language model.\n",
    "\n",
    "    Given a prompt and an n-gram frequency dictionary, this function continues the text\n",
    "    by repeatedly sampling the next word based on the previous (n-1) words. The response\n",
    "    generation stops either after reaching max_length words or when the <END> is produced.\n",
    "\n",
    "    Args:\n",
    "        prompt (str): The starting text to build the response from.\n",
    "        ngram_counts (dict): A dictionary where keys are (n-1)-tuples of words and values\n",
    "                             are dictionaries mapping possible next words to their counts.\n",
    "        n (int): The 'n' in NGram (e.g., 2 for bigrams, 3 for trigrams).\n",
    "        max_length (int): The maximum number of words to generate.\n",
    "\n",
    "    Returns:\n",
    "        str: A generated text response.\n",
    "    \"\"\"\n",
    "    print(\"Hello! I'm a simple chatbot. Let's chat!\")\n",
    "    print(\"(Type 'quit' to end the conversation)\\n\")\n",
    "    \n",
    "    while True:\n",
    "        user_input = input(\"\\nYou: \")\n",
    "        \n",
    "        if user_input.lower() == 'quit':\n",
    "            print(\"Chatbot: Goodbye! Thanks for chatting!\")\n",
    "            return\n",
    "\n",
    "        if not user_input.strip():\n",
    "            print(\"Chatbot: I'm listening...\") # If there is an empty input, re-prompt\n",
    "            continue\n",
    "        \n",
    "        response = generate_ngram_response(user_input, word_counts, n)\n",
    "        \n",
    "        print(f\"Chatbot: \", response, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777f6184",
   "metadata": {},
   "source": [
    "Run the cell below to interact with the chatbot!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef28f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_ngram_chatbot(trigram_counts, 3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "convokit_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
